<!DOCTYPE html>
<html lang="en" dir="auto" data-theme="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Compliance Does Not Mean Complacent: How I Silenced 83% of Our Alert Noise | Andy Gallegos</title>
<meta name="keywords" content="PowerShell, GRC, Exchange, Automation, Compliance">
<meta name="description" content="How I used PowerShell to audit Exchange logs, identifying that 83% of our alert volume was technical debt masquerading as compliance.">
<meta name="author" content="">
<link rel="canonical" href="https://andygallegos.com/posts/noisy_senders/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.a29c24210eb31d9ce56f669c66a35c9c51b17376b7764e336a49af7dec914cf0.css" integrity="sha256-opwkIQ6zHZzlb2acZqNcnFGxc3a3dk4zakmvfeyRTPA=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://andygallegos.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://andygallegos.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://andygallegos.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://andygallegos.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://andygallegos.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://andygallegos.com/posts/noisy_senders/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
                color-scheme: dark;
            }

            .list {
                background: var(--theme);
            }

            .toc {
                background: var(--entry);
            }
        }

        @media (prefers-color-scheme: light) {
            .list::-webkit-scrollbar-thumb {
                border-color: var(--code-bg);
            }
        }

    </style>
</noscript>
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.querySelector("html").dataset.theme = 'dark';
    } else if (localStorage.getItem("pref-theme") === "light") {
       document.querySelector("html").dataset.theme = 'light';
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.querySelector("html").dataset.theme = 'dark';
    } else {
        document.querySelector("html").dataset.theme = 'light';
    }

</script><meta property="og:url" content="https://andygallegos.com/posts/noisy_senders/">
  <meta property="og:site_name" content="Andy Gallegos">
  <meta property="og:title" content="Compliance Does Not Mean Complacent: How I Silenced 83% of Our Alert Noise">
  <meta property="og:description" content="How I used PowerShell to audit Exchange logs, identifying that 83% of our alert volume was technical debt masquerading as compliance.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2026-01-29T10:00:00-05:00">
    <meta property="article:modified_time" content="2026-01-29T10:00:00-05:00">
    <meta property="article:tag" content="PowerShell">
    <meta property="article:tag" content="GRC">
    <meta property="article:tag" content="Exchange">
    <meta property="article:tag" content="Automation">
    <meta property="article:tag" content="Compliance">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Compliance Does Not Mean Complacent: How I Silenced 83% of Our Alert Noise">
<meta name="twitter:description" content="How I used PowerShell to audit Exchange logs, identifying that 83% of our alert volume was technical debt masquerading as compliance.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blog",
      "item": "https://andygallegos.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Compliance Does Not Mean Complacent: How I Silenced 83% of Our Alert Noise",
      "item": "https://andygallegos.com/posts/noisy_senders/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Compliance Does Not Mean Complacent: How I Silenced 83% of Our Alert Noise",
  "name": "Compliance Does Not Mean Complacent: How I Silenced 83% of Our Alert Noise",
  "description": "How I used PowerShell to audit Exchange logs, identifying that 83% of our alert volume was technical debt masquerading as compliance.",
  "keywords": [
    "PowerShell", "GRC", "Exchange", "Automation", "Compliance"
  ],
  "articleBody": "In the world of DoD contracting and high-security infrastructure, “Compliance” is mandatory. Because of this, there will often be little to no discussion about the nuances. Simply put, meeting compliance is the goal and meeting it is good enough. We log everything. We alert on everything. Because a STIG says that we must.\nI had a difficult time adjusting to this, but noise has always been a problem in any IT environment I have been a part of. Especially in our environment. “If the STIG says so, then we don’t have a say”. And so we dealt with the rules and the noise and the flooded folders and occasional errant alert storms.\nAnd this worked fine as we focused on growth, because you can fine tune things AFTER you reach your goal, right? But in the mean time, we were getting complacement and lazy. THere is simply no other way to put it. Our team was receiving hundreds of operational alerts daily - snapshots, backup notifications, service hiccups - and the volume was so high that it triggered a collective analsysis paralysis where everyone knew there were a lot of alerts but no one paid attention to them, even as we were getting slammed with them.\nBut this isn’t operational maturity. It isn’t even basic best practice and after my mailbox exploded one day, I decided to take on the task of fixing this.\nIdeally, an entire revamp of our monitoring system would be ideal. Zabbix or Nagios. Proper ITSM. But we aren’t there yet and even if we got everything we wanted today, we were still engaging in lazy bad practice. Instead of 20 services sending 100 emails, we’d have 1 server sending 200 emails.\nI decided to stop clearing the inbox and start auditing it. Here is how I used PowerShell to turn noise back into signal.\nHuge shoutout the Embrace The Red who helped give me an organizational and operational framework that went beyond technical: https://embracethered.com/blog/posts/2025/the-normalization-of-deviance-in-ai/\nThe Problem: The “Compliance” Trap The issue wasn’t just annoyance; it was data integrity. When I looked at our alerts and started asking questions, I realized something. We were qietly normalizing warning signs while progress marches forward. In other words, past success and future progress was what we used to shape our risk tolerance. You know things are setting up for disaster when the blinking lights are ignored. All it takes is one really meaningful alert to sneak by to bring things down.\n“We were qietly normalizing warning signs while progress marches forward.”\n— https://embracethered.com/blog/posts/2025/the-normalization-of-deviance-in-ai/\nThe Solution: PowerShell as an Auditor I turned to the raw Exchange Transport Logs. At first I tried looking for the sending domains with the highest count. But this only showed numbers, not behaviors.\nI wrote a PowerShell script to parse the logs, but I made a crucial architectural decision: I filtered by the RECEIVE EventID, not DELIVER.\nDELIVER tells you how many people got the email (e.g., 10 recipients = 10 logs). RECEIVE tells you how many times the device physically connected to the server. This distinction was the key to the entire investigation.\nThe Analysis Script Here is the core logic I used to audit the traffic. It groups traffic by “Sender” and “Subject” to identify the noisiest talkers, while filtering out known-good traffic.\n$StartDate = (Get-Date).AddHours(-24) $EndDate = Get-Date # Filter for RECEIVE events to spot connection volume, not email volume Get-ExchangeServer | Get-MessageTrackingLog -ResultSize Unlimited -EventId RECEIVE -Start $StartDate -End $EndDate | Where-Object { $_.Sender -like \"*@domain1.com\" } | Group-Object -Property Sender, MessageSubject | Sort-Object Count -Descending | Select-Object Count, @{Name=\"Sender\"; Expression={$_.Group[0].Sender}}, @{Name=\"Subject\"; Expression={$_.Group[0].MessageSubject}} | Format-Table -AutoSize The “Micro-Burst” Discovery My script uncovered a massive discrepancy. I found a single system generating 10 separate SMTP connections per second to send the exact same alert to 10 different people.\nI quickly realized that we were facing an architectural issue. They alerts were made to satisfy compliance, not actually alert people.\nInstead of sending one email to a Distribution List, the device was looping through a list of admins and initiating a new TCP handshake for every single one. It was effectively launching a micro-Denial of Service (DoS) attack on our own Exchange Receive Connectors every time it wanted to say “Hello.”\nBefore \u0026 After: The Data Once we identified the “looping” behaviors and the “Status Update” spam, the metrics were undeniable:\nBefore: A 24-hour window showed 600+ alerts. The team assumed the network was unstable and the servers were on fire. The Reality: My analysis proved these 600 alerts were actually just 60 unique events, inflated by poor configuration and “Reply All” logic. After: By fixing the application loops and tuning the alert thresholds (e.g., “Alert only if snapshot \u003e 72 hours”), we reduced volume by 83%. Conclusion True compliance isn’t about having the logs; it’s about having the reaction.\nAlerts were not something meaningful and impactful. We didn’t look at inbox folder ABC and see 1200 unread emails. We now saw 1 and immediately checked it out.\nI didn’t prevent the sky from falling, as much as I’d like to pretend I did. All I did was clean up some technical debt with one afternoon playing around with Exchange Management Shell. But it made such a large operational impact that I felt it was worth sharing.\n",
  "wordCount" : "884",
  "inLanguage": "en",
  "datePublished": "2026-01-29T10:00:00-05:00",
  "dateModified": "2026-01-29T10:00:00-05:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://andygallegos.com/posts/noisy_senders/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Andy Gallegos",
    "logo": {
      "@type": "ImageObject",
      "url": "https://andygallegos.com/favicon.ico"
    }
  }
}
</script>
</head>
<body id="top">
    <header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://andygallegos.com/" accesskey="h" title="Andy Gallegos (Alt + H)">Andy Gallegos</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://andygallegos.com/compliance" title="Compliance Matrix">
                    <span>Compliance Matrix</span>
                </a>
            </li>
            <li>
                <a href="https://andygallegos.com/posts/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Compliance Does Not Mean Complacent: How I Silenced 83% of Our Alert Noise
    </h1>
    <div class="post-meta"><span title='2026-01-29 10:00:00 -0500 EST'>January 29, 2026</span>&nbsp;·&nbsp;<span>5 min</span>

</div>
  </header> 
  <div class="post-content"><p>In the world of DoD contracting and high-security infrastructure, &ldquo;Compliance&rdquo; is mandatory.  Because of this, there will often be little to no discussion about the nuances.  Simply put, meeting compliance is the goal and meeting it is good enough.   We log everything. We alert on everything.  Because a STIG says that we must.</p>
<p>I had a difficult time adjusting to this, but noise has always been a problem in any IT environment I have been a part of.  Especially in our environment.  &ldquo;If the STIG says so, then we don&rsquo;t have a say&rdquo;.  And so we dealt with the rules and the noise and the flooded folders and occasional errant alert storms.</p>
<p>And this worked fine as we focused on growth, because you can fine tune things AFTER you reach your goal, right?  But in the mean time, we were getting complacement and lazy.  THere is simply no other way to put it.  Our team was receiving hundreds of operational alerts daily - snapshots, backup notifications, service hiccups - and the volume was so high that it triggered a collective analsysis paralysis where everyone knew there were a lot of alerts but no one paid attention to them, even as we were getting slammed with them.</p>
<p>But this isn&rsquo;t operational maturity.  It isn&rsquo;t even basic best practice and after my mailbox exploded one day, I decided to take on the task of fixing this.</p>
<p>Ideally, an entire revamp of our monitoring system would be ideal.  Zabbix or Nagios.  Proper ITSM.  But we aren&rsquo;t there yet and even if we got everything we wanted today, we were still engaging in lazy bad practice.  Instead of 20 services sending 100 emails, we&rsquo;d have 1 server sending 200 emails.</p>
<p>I decided to stop clearing the inbox and start auditing it. Here is how I used PowerShell to turn noise back into signal.</p>
<p>Huge shoutout the Embrace The Red who helped give me an organizational and operational framework that went beyond technical: <a href="https://embracethered.com/blog/posts/2025/the-normalization-of-deviance-in-ai/">https://embracethered.com/blog/posts/2025/the-normalization-of-deviance-in-ai/</a></p>
<h2 id="the-problem-the-compliance-trap">The Problem: The &ldquo;Compliance&rdquo; Trap<a hidden class="anchor" aria-hidden="true" href="#the-problem-the-compliance-trap">#</a></h2>
<p>The issue wasn&rsquo;t just annoyance; it was data integrity. When I looked at our alerts and started asking questions, I realized something.  We were qietly normalizing warning signs while progress marches forward.  In other words, past success and future progress was what we used to shape our risk tolerance.  You know things are setting up for disaster when the blinking lights are ignored.   All it takes is one really meaningful alert to sneak by to bring things down.</p>
<blockquote>
<p>&ldquo;We were qietly normalizing warning signs while progress marches forward.&rdquo;</p>
<p>— <em><a href="https://embracethered.com/blog/posts/2025/the-normalization-of-deviance-in-ai/">https://embracethered.com/blog/posts/2025/the-normalization-of-deviance-in-ai/</a></em></p>
</blockquote>
<h2 id="the-solution-powershell-as-an-auditor">The Solution: PowerShell as an Auditor<a hidden class="anchor" aria-hidden="true" href="#the-solution-powershell-as-an-auditor">#</a></h2>
<p>I turned to the raw Exchange Transport Logs. At first I tried looking for the sending domains with the highest count.  But this only showed numbers, not behaviors.</p>
<p>I wrote a PowerShell script to parse the logs, but I made a crucial architectural decision: I filtered by the <code>RECEIVE</code> EventID, not <code>DELIVER</code>.</p>
<ul>
<li><strong>DELIVER</strong> tells you how many people got the email (e.g., 10 recipients = 10 logs).</li>
<li><strong>RECEIVE</strong> tells you how many times the device physically connected to the server.</li>
</ul>
<p>This distinction was the key to the entire investigation.</p>
<h3 id="the-analysis-script">The Analysis Script<a hidden class="anchor" aria-hidden="true" href="#the-analysis-script">#</a></h3>
<p>Here is the core logic I used to audit the traffic. It groups traffic by &ldquo;Sender&rdquo; and &ldquo;Subject&rdquo; to identify the noisiest talkers, while filtering out known-good traffic.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-powershell" data-lang="powershell"><span style="display:flex;"><span>$StartDate = (Get-Date).AddHours(<span style="color:#ae81ff">-24</span>)
</span></span><span style="display:flex;"><span>$EndDate   = Get-Date
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Filter for RECEIVE events to spot connection volume, not email volume</span>
</span></span><span style="display:flex;"><span>Get-ExchangeServer | Get-MessageTrackingLog -ResultSize Unlimited -EventId RECEIVE -Start $StartDate -End $EndDate |
</span></span><span style="display:flex;"><span>    Where-Object { $_.Sender <span style="color:#f92672">-like</span> <span style="color:#e6db74">&#34;*@domain1.com&#34;</span> } |
</span></span><span style="display:flex;"><span>    Group-Object -Property Sender, MessageSubject |
</span></span><span style="display:flex;"><span>    Sort-Object Count -Descending |
</span></span><span style="display:flex;"><span>    Select-Object Count, 
</span></span><span style="display:flex;"><span>                  @{Name=<span style="color:#e6db74">&#34;Sender&#34;</span>; Expression={$_.Group[<span style="color:#ae81ff">0</span>].Sender}}, 
</span></span><span style="display:flex;"><span>                  @{Name=<span style="color:#e6db74">&#34;Subject&#34;</span>; Expression={$_.Group[<span style="color:#ae81ff">0</span>].MessageSubject}} |
</span></span><span style="display:flex;"><span>    Format-Table -AutoSize
</span></span></code></pre></div><p><a href="https://github.com/GrandeAnde/Portfolio/blob/main/Exchange/noisy_senders.ps1"><img alt="View the full script GitHub" loading="lazy" src="https://img.shields.io/badge/View_Full_Script-GitHub-black?logo=github&style=for-the-badge"></a></p>
<h2 id="the-micro-burst-discovery">The &ldquo;Micro-Burst&rdquo; Discovery<a hidden class="anchor" aria-hidden="true" href="#the-micro-burst-discovery">#</a></h2>
<p>My script uncovered a massive discrepancy. I found a single system generating <strong>10 separate SMTP connections per second</strong> to send the exact same alert to 10 different people.</p>
<p>I quickly realized that we were facing an architectural issue.  They alerts were made to satisfy compliance, not actually alert people.</p>
<p>Instead of sending one email to a Distribution List, the device was looping through a list of admins and initiating a new TCP handshake for every single one. It was effectively launching a micro-Denial of Service (DoS) attack on our own Exchange Receive Connectors every time it wanted to say &ldquo;Hello.&rdquo;</p>
<h2 id="before--after-the-data">Before &amp; After: The Data<a hidden class="anchor" aria-hidden="true" href="#before--after-the-data">#</a></h2>
<p>Once we identified the &ldquo;looping&rdquo; behaviors and the &ldquo;Status Update&rdquo; spam, the metrics were undeniable:</p>
<ul>
<li><strong>Before:</strong> A 24-hour window showed <strong>600+ alerts</strong>. The team assumed the network was unstable and the servers were on fire.</li>
<li><strong>The Reality:</strong> My analysis proved these 600 alerts were actually just <strong>60 unique events</strong>, inflated by poor configuration and &ldquo;Reply All&rdquo; logic.</li>
<li><strong>After:</strong> By fixing the application loops and tuning the alert thresholds (e.g., &ldquo;Alert only if snapshot &gt; 72 hours&rdquo;), we reduced volume by <strong>83%</strong>.</li>
</ul>
<h2 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h2>
<p>True compliance isn&rsquo;t about having the logs; it&rsquo;s about having the <em>reaction</em>.</p>
<p>Alerts were not something meaningful and impactful.  We didn&rsquo;t look at inbox folder ABC and see 1200 unread emails.  We now saw 1 and immediately checked it out.</p>
<p>I didn&rsquo;t prevent the sky from falling, as much as I&rsquo;d like to pretend I did.  All I did was clean up some technical debt with one afternoon playing around with Exchange Management Shell.  But it made such a large operational impact that I felt it was worth sharing.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://andygallegos.com/tags/powershell/">PowerShell</a></li>
      <li><a href="https://andygallegos.com/tags/grc/">GRC</a></li>
      <li><a href="https://andygallegos.com/tags/exchange/">Exchange</a></li>
      <li><a href="https://andygallegos.com/tags/automation/">Automation</a></li>
      <li><a href="https://andygallegos.com/tags/compliance/">Compliance</a></li>
    </ul>
<nav class="paginav">
  <a class="next" href="https://andygallegos.com/posts/cmmc-static-site/">
    <span class="title">Next »</span>
    <br>
    <span>Building a Personal Website: A GitOps Approach</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2026 <a href="https://andygallegos.com/">Andy Gallegos</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu');
    if (menu) {
        
        const scrollPosition = localStorage.getItem("menu-scroll-position");
        if (scrollPosition) {
            menu.scrollLeft = parseInt(scrollPosition, 10);
        }
        
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        const html = document.querySelector("html");
        if (html.dataset.theme === "dark") {
            html.dataset.theme = 'light';
            localStorage.setItem("pref-theme", 'light');
        } else {
            html.dataset.theme = 'dark';
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
